"""
STRM æ–‡ä»¶ç”Ÿæˆå·¥å…·

ğŸ”¥ æ ¸å¿ƒè®¾è®¡ï¼ˆè§ docs/CONTEXT.mdï¼‰ï¼š
- connect_strm_targetï¼šè¿æ¥ STRM ç›®æ ‡å­˜å‚¨
- generate_strmï¼šç”Ÿæˆ STRM æ–‡ä»¶ï¼ˆåˆå¹¶ TV + ç”µå½±ï¼‰

æ•°æ®æ¥æºï¼š
- state.classificationsï¼ˆç”± analyze_and_classify å†™å…¥ï¼‰

è¾“å‡ºè·¯å¾„æ ¼å¼ï¼ˆInfuse å…¼å®¹ï¼‰ï¼š
- TV: /root_path/å‰§é›†/å­åˆ†ç±»/ç³»åˆ—å (å¹´)/Season XX/ç³»åˆ—å.SXX.EXX.strm
- ç”µå½±: /root_path/ç”µå½±/å­åˆ†ç±»/ç”µå½±å (å¹´)/ç”µå½±å (å¹´).strm

å­åˆ†ç±»ï¼š
- æ ¹æ® TMDB Genres è‡ªåŠ¨åˆ¤æ–­ï¼ˆåŠ¨æ¼«/çºªå½•ç‰‡/éŸ³ä¹/ç»¼è‰º/é»˜è®¤ï¼‰

æ€§èƒ½ä¼˜åŒ–ï¼š
- ä½¿ç”¨æœåŠ¡å±‚çš„ upload_files_batch_async å®ç° 16 åç¨‹å¹¶å‘ä¸Šä¼ 
- ğŸ†• å­—å¹•å¤„ç†ï¼šä¸‹è½½å’Œä¸Šä¼ å°è£…ä¸ºå•ä¸ªå¹¶å‘ä»»åŠ¡ï¼Œé¿å…å…ˆå…¨éƒ¨ä¸‹è½½å†ä¸Šä¼ 

ğŸ”¥ æ–°æ¶æ„ï¼ˆ2026-01-08ï¼‰ï¼š
- ä½¿ç”¨ InjectedState è®¿é—® State
- è¿”å›é€šç”¨ ToolResponse JSONï¼š{"message": "...", "state_update": {...}}
- ä½¿ç”¨ services.py ç®¡ç†æœåŠ¡å®ä¾‹
"""

import os
import io
import time
import zipfile
import traceback

from backend.agents.state import MediaAgentState
import logging
import asyncio
from typing import Dict, Any, List, Annotated, Optional, Tuple
from urllib.parse import quote
from dataclasses import dataclass
from langchain.tools import tool
from langgraph.prebuilt import InjectedState

from backend.agents.state import MediaAgentState
from backend.agents.services import get_storage_service, get_strm_target_service, cache_strm_service
from backend.agents.tool_response import make_tool_response
from backend.services.tmdb_service import get_tmdb_service
from backend.services.storage_factory import create_storage_service_sync
from backend.utils.naming import (
    format_strm_episode_name,
    format_strm_movie_name,
    format_series_folder,
    format_season_folder,
    format_movie_folder,
)
from backend.agents.models import (
    MediaType, SubCategory, determine_subcategory, SubtitleFile,
    Classification, ClassifiedFile
)
from backend.utils.path_utils import get_target_path


# ğŸ”¥ å­—å¹•è¯­è¨€ä¼˜å…ˆçº§ï¼ˆç”¨äºé€‰æ‹©é»˜è®¤å­—å¹•ï¼‰
SUBTITLE_LANGUAGE_PRIORITY = [
    'chs', 'sc', 'chsjp', 'scjp',  # ç®€ä¸­ä¼˜å…ˆ
    'cht', 'tc', 'chtjp', 'tcjp',  # ç¹ä¸­æ¬¡ä¹‹
    'eng', 'en',                   # è‹±æ–‡
    'jpn', 'jap', 'jp',            # æ—¥æ–‡
    'und',                         # æœªçŸ¥
]

# ğŸ†• å­—å¹•å¹¶å‘å¤„ç†é…ç½®
SUBTITLE_DOWNLOAD_CONCURRENCY = 8  # ä¸‹è½½å¹¶å‘æ•°
SUBTITLE_UPLOAD_CONCURRENCY = 16   # ä¸Šä¼ å¹¶å‘æ•°


@dataclass
class SubtitleTask:
    """å­—å¹•å¤„ç†ä»»åŠ¡"""
    source_path: str      # æºæ–‡ä»¶è·¯å¾„ï¼ˆä»æºå­˜å‚¨è¯»å–ï¼‰
    target_path: str      # ç›®æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆå†™å…¥ç›®æ ‡å­˜å‚¨ï¼‰
    is_default: bool      # æ˜¯å¦ä¸ºé»˜è®¤å­—å¹•


def _get_language_priority(lang: str) -> int:
    """è·å–è¯­è¨€ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰"""
    lang_lower = lang.lower() if lang else 'und'
    try:
        return SUBTITLE_LANGUAGE_PRIORITY.index(lang_lower)
    except ValueError:
        return 999  # æœªçŸ¥è¯­è¨€æ”¾æœ€å


def _format_subtitle_name(title: str, season: int, episode: int, sub: SubtitleFile, is_default: bool = False) -> str:
    """æ ¼å¼åŒ–å­—å¹•æ–‡ä»¶å
    
    æ ¼å¼: ç³»åˆ—å.Sxx.Exx.è¯­è¨€.æ‰©å±•åï¼ˆä¸ STRM æ–‡ä»¶åæ ¼å¼ä¸€è‡´ï¼‰
    ä¾‹å¦‚: SeriesA.S01.E01.chs.srt
    
    Args:
        title: ç³»åˆ—å
        season: å­£å·
        episode: é›†å·
        sub: å­—å¹•æ–‡ä»¶
        is_default: æ˜¯å¦ä¸ºé»˜è®¤å­—å¹•ï¼ˆä¸å¸¦è¯­è¨€æ ‡è¯†ï¼‰
    """
    # ä»åŸå§‹æ–‡ä»¶åè·å–æ‰©å±•å
    ext = os.path.splitext(sub.name)[1].lower()  # .srt, .ass, .ssa
    
    if is_default:
        # ğŸ†• é»˜è®¤å­—å¹•ä¸å¸¦è¯­è¨€æ ‡è¯†ï¼Œæ ¼å¼ä¸ STRM ä¸€è‡´ï¼šS01.E01
        return f"{title}.S{season:02d}.E{episode:02d}{ext}"
    else:
        lang = sub.language or "und"
        # ğŸ”§ æ ¼å¼ä¸ STRM ä¸€è‡´ï¼šS01.E01.lang
        return f"{title}.S{season:02d}.E{episode:02d}.{lang}{ext}"


def _format_movie_subtitle_name(title: str, year: int, sub: SubtitleFile, is_default: bool = False) -> str:
    """æ ¼å¼åŒ–ç”µå½±å­—å¹•æ–‡ä»¶å
    
    æ ¼å¼: ç”µå½±å.å¹´ä»½.è¯­è¨€.æ‰©å±•åï¼ˆä¸ STRM æ–‡ä»¶ format_strm_movie_name ä¸€è‡´ï¼‰
    ä¾‹å¦‚: MovieA.2011.chs.srt
    
    Args:
        title: ç”µå½±å
        year: å¹´ä»½
        sub: å­—å¹•æ–‡ä»¶
        is_default: æ˜¯å¦ä¸ºé»˜è®¤å­—å¹•ï¼ˆä¸å¸¦è¯­è¨€æ ‡è¯†ï¼‰
    """
    from backend.utils.naming import sanitize_filename
    clean_title = sanitize_filename(title)
    clean_title = clean_title.replace(' ', '.')  # ä¸ format_movie_name ä¸€è‡´
    ext = os.path.splitext(sub.name)[1].lower()
    
    if is_default:
        # ğŸ”§ ä¸ format_strm_movie_name æ ¼å¼ä¸€è‡´ï¼šç”µå½±å.å¹´ä»½.ext
        if year:
            return f"{clean_title}.{year}{ext}"
        return f"{clean_title}{ext}"
    else:
        lang = sub.language or "und"
        # ğŸ”§ ä¸ format_strm_movie_name æ ¼å¼ä¸€è‡´ï¼šç”µå½±å.å¹´ä»½.lang.ext
        if year:
            return f"{clean_title}.{year}.{lang}{ext}"
        return f"{clean_title}.{lang}{ext}"


def _select_default_subtitle(subtitles: list) -> SubtitleFile:
    """æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©é»˜è®¤å­—å¹•
    
    Args:
        subtitles: å­—å¹•æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        ä¼˜å…ˆçº§æœ€é«˜çš„å­—å¹•
    """
    if not subtitles:
        return None
    
    return min(subtitles, key=lambda s: _get_language_priority(s.language))

logger = logging.getLogger(__name__)

# å¹¶å‘ä¸Šä¼ é…ç½®
UPLOAD_CONCURRENCY = 16


# ============ è¾…åŠ©å‡½æ•° ============

def _build_play_url(base_url: str, file_path: str, storage_type: str) -> str:
    """æ„å»ºæ’­æ”¾ URLï¼ˆæ ¹æ®å­˜å‚¨ç±»å‹ï¼‰
    
    ä½¿ç”¨ JavaScript encodeURI å…¼å®¹çš„ç¼–ç æ–¹å¼ï¼š
    - ä¸ç¼–ç ï¼šA-Z a-z 0-9 - _ . ! ~ * ' ( ) ; / ? : @ & = + $ , #
    - ç¼–ç ï¼š[] ç©ºæ ¼ ä¸­æ–‡ åŠå…¶ä»–ç‰¹æ®Šå­—ç¬¦
    
    Args:
        base_url: å­˜å‚¨æœåŠ¡å™¨åœ°å€
        file_path: æ–‡ä»¶è·¯å¾„
        storage_type: å­˜å‚¨ç±»å‹ ("alist" æˆ– "webdav")
    
    Returns:
        å¯æ’­æ”¾çš„ URL
    """
    # ğŸ”¥ æ¨¡æ‹Ÿ JavaScript encodeURI è¡Œä¸º
    # encodeURI ä¸ç¼–ç çš„å­—ç¬¦ï¼ˆé™¤å­—æ¯æ•°å­—å¤–ï¼‰ï¼š- _ . ! ~ * ' ( ) ; / ? : @ & = + $ , #
    # æ³¨æ„ï¼š[] ä¼šè¢«ç¼–ç ä¸º %5B%5Dï¼ˆè¿™æ˜¯æ­£ç¡®çš„ï¼æ’­æ”¾å™¨éœ€è¦è¿™æ ·ï¼‰
    ENCODE_URI_SAFE = "-_.!~*'();/?:@&=+$,#"
    encoded_path = quote(file_path, safe=ENCODE_URI_SAFE)
    base = base_url.rstrip('/')
    
    if storage_type == "alist":
        # Alist: ä½¿ç”¨ /d/ ç›´æ¥ä¸‹è½½æ ¼å¼ï¼ˆé«˜æ•ˆï¼Œæ— éœ€ API è°ƒç”¨ï¼‰
        return f"{base}/d{encoded_path}"
    else:
        # WebDAV: ä½¿ç”¨ /dav/ æ ¼å¼ï¼ˆæ ‡å‡† WebDAV è·¯å¾„ï¼‰
        return f"{base}/dav{encoded_path}"


def _generate_strm_content(storage_config: Dict[str, Any], file_path: str) -> str:
    """ç”Ÿæˆ STRM æ–‡ä»¶å†…å®¹
    
    è‡ªåŠ¨æ ¹æ®æºå­˜å‚¨ç±»å‹ç”Ÿæˆæ­£ç¡®çš„æ’­æ”¾ URL
    ä» storage_config è¯»å– url å’Œ type
    """
    base_url = storage_config.get('url', '')
    storage_type = storage_config.get('type', 'webdav')
    return _build_play_url(base_url, file_path, storage_type)


def _read_subtitle_content(service, sub_path: str) -> Optional[str]:
    """ä»æºå­˜å‚¨è¯»å–å­—å¹•æ–‡ä»¶å†…å®¹
    
    Args:
        service: æºå­˜å‚¨æœåŠ¡å®ä¾‹
        sub_path: å­—å¹•æ–‡ä»¶è·¯å¾„
        
    Returns:
        å­—å¹•å†…å®¹ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    try:
        content = service.get_file_content(sub_path)
        if content:
            return content
        else:
            logger.warning(f"è¯»å–å­—å¹•å¤±è´¥: {sub_path}")
            return None
    except Exception as e:
        logger.warning(f"è¯»å–å­—å¹•å¼‚å¸¸ {sub_path}: {e}")
        return None


@dataclass
class SubtitleTaskResult:
    """å­—å¹•ä»»åŠ¡ç»“æœ"""
    success: bool
    source_path: str
    target_path: str
    error: Optional[str] = None


async def _process_subtitle_task_async(
    task: SubtitleTask,
    source_service,
    target_service,
    semaphore: asyncio.Semaphore
) -> SubtitleTaskResult:
    """
    ğŸ†• å¼‚æ­¥å¤„ç†å•ä¸ªå­—å¹•ä»»åŠ¡ï¼ˆä¸‹è½½ + ä¸Šä¼ ä½œä¸ºä¸€ä¸ªåŸå­æ“ä½œï¼‰
    
    Args:
        task: å­—å¹•ä»»åŠ¡
        source_service: æºå­˜å‚¨æœåŠ¡
        target_service: ç›®æ ‡å­˜å‚¨æœåŠ¡
        semaphore: å¹¶å‘æ§åˆ¶ä¿¡å·é‡
        
    Returns:
        SubtitleTaskResult åŒ…å«æˆåŠŸçŠ¶æ€ã€è·¯å¾„å’Œé”™è¯¯ä¿¡æ¯
    """
    async with semaphore:
        try:
            # 1. å¼‚æ­¥ä¸‹è½½å­—å¹•å†…å®¹
            logger.debug(f"ğŸ“¥ å¼€å§‹ä¸‹è½½å­—å¹•: {task.source_path}")
            content = await source_service.get_file_content_async(task.source_path)
            if not content:
                error_msg = "ä¸‹è½½å¤±è´¥ï¼ˆè¿”å›ç©ºå†…å®¹æˆ–HTTPé”™è¯¯ï¼‰"
                logger.warning(f"âŒ {error_msg}: {task.source_path} -> {task.target_path}")
                return SubtitleTaskResult(
                    success=False,
                    source_path=task.source_path,
                    target_path=task.target_path,
                    error=error_msg
                )
            
            logger.debug(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ å­—å¹•: {task.target_path} (å¤§å°: {len(content)} bytes)")
            
            # 2. ç«‹å³ä¸Šä¼ åˆ°ç›®æ ‡å­˜å‚¨
            success = await target_service.put_file_content_async(task.target_path, content)
            if success:
                logger.debug(f"âœ… å­—å¹•å¤„ç†æˆåŠŸ: {task.source_path} -> {task.target_path}")
                return SubtitleTaskResult(
                    success=True,
                    source_path=task.source_path,
                    target_path=task.target_path
                )
            else:
                error_msg = "ä¸Šä¼ å¤±è´¥ï¼ˆAPIè¿”å›å¤±è´¥ï¼‰"
                logger.warning(f"âŒ {error_msg}: {task.source_path} -> {task.target_path}")
                return SubtitleTaskResult(
                    success=False,
                    source_path=task.source_path,
                    target_path=task.target_path,
                    error=error_msg
                )
                
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ å¤„ç†å­—å¹•å¼‚å¸¸ {task.source_path} -> {task.target_path}: {e}\n{traceback.format_exc()}")
            return SubtitleTaskResult(
                success=False,
                source_path=task.source_path,
                target_path=task.target_path,
                error=error_msg
            )


async def _process_subtitles_batch_async(
    tasks: List[SubtitleTask],
    source_service,
    target_service,
    concurrency: int = SUBTITLE_UPLOAD_CONCURRENCY
) -> Tuple[int, int, List[str], List[Dict[str, Any]]]:
    """
    ğŸ†• æ‰¹é‡å¹¶å‘å¤„ç†å­—å¹•ä»»åŠ¡ï¼ˆä¸‹è½½+ä¸Šä¼ å°è£…ä¸ºå•ä¸ªä»»åŠ¡ï¼‰
    
    Args:
        tasks: å­—å¹•ä»»åŠ¡åˆ—è¡¨
        source_service: æºå­˜å‚¨æœåŠ¡
        target_service: ç›®æ ‡å­˜å‚¨æœåŠ¡
        concurrency: å¹¶å‘æ•°
        
    Returns:
        (æˆåŠŸæ•°, å¤±è´¥æ•°, å¤±è´¥è·¯å¾„åˆ—è¡¨, å¤±è´¥è¯¦æƒ…åˆ—è¡¨)
    """
    if not tasks:
        return (0, 0, [], [])
    
    semaphore = asyncio.Semaphore(concurrency)
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(
        *[_process_subtitle_task_async(task, source_service, target_service, semaphore) 
          for task in tasks],
        return_exceptions=True
    )
    
    success_count = 0
    error_count = 0
    failed_paths = []
    failed_details = []  # ğŸ†• è¯¦ç»†å¤±è´¥ä¿¡æ¯
    
    for result in results:
        if isinstance(result, Exception):
            error_count += 1
            logger.error(f"å­—å¹•ä»»åŠ¡å¼‚å¸¸: {result}")
        elif isinstance(result, SubtitleTaskResult):
            if result.success:
                success_count += 1
            else:
                error_count += 1
                failed_paths.append(result.target_path)
                # ğŸ†• æ”¶é›†è¯¦ç»†å¤±è´¥ä¿¡æ¯
                failed_details.append({
                    "source_path": result.source_path,
                    "target_path": result.target_path,
                    "type": "subtitle",
                    "error": result.error or "æœªçŸ¥é”™è¯¯"
                })
        else:
            error_count += 1
    
    return (success_count, error_count, failed_paths, failed_details)


def _parse_classifications(classifications_data: List[Dict[str, Any]]) -> Dict[int, Classification]:
    """ä» State ä¸­è§£æ classifications æ•°æ®ä¸º Pydantic æ¨¡å‹"""
    result = {}
    for cls_dict in classifications_data:
        tmdb_id = cls_dict.get("tmdb_id")
        if tmdb_id:
            # è§£æ seasons
            seasons = {}
            for season_num, files_data in cls_dict.get("seasons", {}).items():
                season_files = []
                for f in files_data:
                    subtitles = [SubtitleFile(**s) for s in f.get("subtitles", [])]
                    season_files.append(ClassifiedFile(
                        path=f["path"],
                        name=f["name"],
                        episode=f.get("episode", 0),
                        season=f.get("season", 0),
                        subtitles=subtitles
                    ))
                seasons[int(season_num)] = season_files
            
            # è§£æ files (for movies)
            files = []
            for f in cls_dict.get("files", []):
                subtitles = [SubtitleFile(**s) for s in f.get("subtitles", [])]
                files.append(ClassifiedFile(
                    path=f["path"],
                    name=f["name"],
                    episode=f.get("episode", 0),
                    season=f.get("season", 0),
                    subtitles=subtitles
                ))
            
            result[tmdb_id] = Classification(
                tmdb_id=tmdb_id,
                name=cls_dict.get("name", ""),
                type=MediaType(cls_dict.get("type", "tv")),
                year=cls_dict.get("year"),
                genres=cls_dict.get("genres", []),
                sub_category=SubCategory(cls_dict.get("sub_category", "default")),
                seasons=seasons,
                files=files
            )
    return result


# ============ å·¥å…·å‡½æ•° ============

@tool
def connect_strm_target(
    url: str,
    username: str,
    password: str,
    target_path: str = "/",
    state: Annotated[dict, InjectedState] = None,
) -> str:
    """
    è¿æ¥ STRM ç›®æ ‡å­˜å‚¨
    
    è¿™æ˜¯ generate_strm çš„å‰ç½®æ­¥éª¤ã€‚è¿æ¥åï¼Œgenerate_strm ä¼šå°†æ–‡ä»¶ä¸Šä¼ åˆ°æ­¤å­˜å‚¨ã€‚
    
    Args:
        url: å­˜å‚¨æœåŠ¡å™¨åœ°å€ï¼ˆæ”¯æŒ Alist å’Œ WebDAVï¼‰
        username: ç”¨æˆ·å
        password: å¯†ç 
        target_path: STRM è¾“å‡ºè·¯å¾„ï¼Œä¾‹å¦‚ "/kuake/strm"
                     ç³»ç»Ÿä¼šè‡ªåŠ¨åœ¨æ­¤è·¯å¾„ä¸‹ç”Ÿæˆåˆ†ç±»ç›®å½•ï¼šå‰§é›†/åŠ¨æ¼«ã€ç”µå½±/åŠ¨æ¼« ç­‰
    
    ğŸ”¥ æ³¨æ„ï¼šä¸Šä¼ å»¶è¿Ÿç”± user_config.upload_delay æ§åˆ¶
    
    Returns:
        ToolResponse JSON
    """
    try:
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        service = create_storage_service_sync(
            url=url,
            username=username,
            password=password,
            base_path="/",  # å›ºå®šä¸ºæ ¹ç›®å½•
        )
        
        # ğŸ”¥ ç«‹å³éªŒè¯è¿æ¥ï¼ˆè§¦å‘ç™»å½•ï¼‰ï¼Œç¡®ä¿æœåŠ¡å·²è®¤è¯
        try:
            service.list_directory("/")
        except Exception as auth_error:
            return make_tool_response(
                f"âŒ è¿æ¥å¤±è´¥: è®¤è¯é”™è¯¯ - {str(auth_error)}\n\nè¯·æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç æ˜¯å¦æ­£ç¡®ã€‚"
            )
        
        strm_target_config = {
            "url": url,
            "target_path": target_path.rstrip('/') if target_path else "/",
            "type": service.service_type,  # ä½¿ç”¨å®é™…æ£€æµ‹çš„ç±»å‹ï¼ˆalist æˆ– webdavï¼‰
            "username": username,
            "password": password,
            "connected": True,  # æ ‡è®°å·²è¿æ¥
        }
        
        # ğŸ”¥ ç¼“å­˜æœåŠ¡å®ä¾‹ï¼Œç¡®ä¿åç»­å·¥å…·å¯ä»¥å¤ç”¨
        cache_strm_service(strm_target_config, service)
        
        return make_tool_response(
            f"âœ… å·²è¿æ¥ STRM ç›®æ ‡å­˜å‚¨\n- URL: {url}\n- è¾“å‡ºè·¯å¾„: {target_path}",
            state_update={"strm_target_config": strm_target_config}
        )
        
    except Exception as e:
        return make_tool_response(f"âŒ è¿æ¥å¤±è´¥: {e}")


@tool
def generate_strm(
    output_format: str = "webdav",
    naming_language: str = "",
    state: Annotated[dict, InjectedState] = None,
) -> str:
    """
    ğŸ”¥ ç”Ÿæˆ STRM æ–‡ä»¶
    
    æ ¹æ® classification ä¸­çš„åˆ†ç±»ç»“æœï¼Œä¸ºæ‰€æœ‰ç³»åˆ—ç”Ÿæˆ STRM æ–‡ä»¶ã€‚
    æ”¯æŒè‡ªåŠ¨å­åˆ†ç±»ï¼šæ ¹æ® TMDB Genres è‡ªåŠ¨å½’ç±»åˆ° åŠ¨æ¼«/çºªå½•ç‰‡/éŸ³ä¹/ç»¼è‰º/é»˜è®¤ã€‚
    ä½¿ç”¨ 16 åç¨‹å¹¶å‘ä¸Šä¼ ï¼Œå¤§å¹…æå‡ä¸Šä¼ é€Ÿåº¦ã€‚
    
    ğŸ”¥ Alist æ’­æ”¾åœ°å€è‡ªåŠ¨ä»æºå­˜å‚¨é…ç½®è¯»å–ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å®šï¼
    
    å‰ç½®æ¡ä»¶ï¼š
    1. å·²ä½¿ç”¨ connect_webdav è¿æ¥æºå­˜å‚¨
    2. å·²ä½¿ç”¨ analyze_and_classify åˆ†ç±»æ–‡ä»¶
    3. å¦‚æœ output_format="webdav"ï¼Œéœ€è¦å…ˆ connect_strm_targetï¼ˆè®¾ç½® target_pathï¼‰
    
    è·¯å¾„ç”Ÿæˆæ–¹å¼ï¼š
    ä½¿ç”¨ strm_target_config.target_path ä½œä¸ºæ ¹è·¯å¾„ï¼Œè‡ªåŠ¨æ ¹æ®å­åˆ†ç±»ç”Ÿæˆå®Œæ•´è·¯å¾„
    ä¾‹å¦‚ï¼štarget_path="/kuake/strm" + Animation â†’ "/kuake/strm/å‰§é›†/åŠ¨æ¼«/..."
    
    Args:
        output_format: è¾“å‡ºæ–¹å¼
            - "webdav": ä¸Šä¼ åˆ°ç›®æ ‡å­˜å‚¨ï¼ˆéœ€è¦å…ˆ connect_strm_targetï¼‰
            - "zip": ç”Ÿæˆ ZIP æ–‡ä»¶ä¸‹è½½
            - "list": ä»…åˆ—å‡ºæ–‡ä»¶ï¼ˆä¸ç”Ÿæˆï¼‰
        naming_language: å‘½åè¯­è¨€ï¼ˆzh/enï¼‰ï¼Œç•™ç©ºåˆ™ä½¿ç”¨ user_config.naming_language
    
    Returns:
        ToolResponse JSON
    """
    # ä» State è¯»å–æ•°æ®
    storage_config = state.get("storage_config", {}) if state else {}
    strm_target_config = state.get("strm_target_config", {}) if state else {}
    user_config = state.get("user_config", {}) if state else {}
    classifications_data = state.get("classifications", []) if state else []
    
    # è§£æ classifications
    classifications = _parse_classifications(classifications_data)
    
    if not classifications:
        return make_tool_response("âŒ è¯·å…ˆä½¿ç”¨ analyze_and_classify åˆ†ç±»æ–‡ä»¶")
    
    if output_format == "webdav" and not strm_target_config.get("connected"):
        return make_tool_response("âŒ è¯·å…ˆä½¿ç”¨ connect_strm_target è¿æ¥ç›®æ ‡å­˜å‚¨")
    
    # ğŸ”¥ æ£€æŸ¥æ˜¯å¦å·²è¿æ¥æºå­˜å‚¨ï¼ˆç”¨äºç”Ÿæˆæ’­æ”¾ URLï¼‰
    if not storage_config.get('url'):
        return make_tool_response("âŒ æœªè¿æ¥æºå­˜å‚¨ã€‚è¯·å…ˆä½¿ç”¨ connect_webdav è¿æ¥å­˜å‚¨æœåŠ¡å™¨")
    
    # ğŸ†• è·å–æºå­˜å‚¨æœåŠ¡å®ä¾‹ï¼ˆç”¨äºè¯»å–å­—å¹•å†…å®¹ï¼‰
    source_service = get_storage_service(state)
    if not source_service:
        return make_tool_response("âŒ æºå­˜å‚¨æœåŠ¡æœªåˆå§‹åŒ–ã€‚è¯·å…ˆä½¿ç”¨ connect_webdav è¿æ¥å­˜å‚¨æœåŠ¡å™¨")
    
    # ä½¿ç”¨ strm_target_config.target_path ä½œä¸ºæ ¹è·¯å¾„
    target_path = strm_target_config.get('target_path', '/') if strm_target_config else '/'
    
    # ä½¿ç”¨ user_config ä¸­çš„é…ç½®ï¼ˆå¦‚æœæœªä¼ å‚ï¼‰
    effective_language = naming_language or user_config.get("naming_language") or "zh"
    
    tmdb = get_tmdb_service()
    all_strm_files = []  # [(è·¯å¾„, å†…å®¹)]
    all_subtitle_tasks: List[SubtitleTask] = []  # ğŸ†• å­—å¹•ä»»åŠ¡åˆ—è¡¨ï¼ˆä¸‹è½½+ä¸Šä¼ å°è£…ä¸ºå•ä¸ªä»»åŠ¡ï¼‰
    
    output = "## ğŸ¬ ç”Ÿæˆ STRM æ–‡ä»¶\n\n"
    output += f"ğŸ“‚ è¾“å‡ºè·¯å¾„: `{target_path}` (è‡ªåŠ¨å­åˆ†ç±»)\n\n"
    
    # éå†æ‰€æœ‰åˆ†ç±»çš„ç³»åˆ—ï¼ˆä½¿ç”¨ Pydantic æ¨¡å‹ï¼‰
    for tmdb_id, cls in classifications.items():
        series_name = cls.name
        series_type = cls.type  # MediaType.TV or MediaType.MOVIE
        year = cls.year
        genres = cls.genres  # TMDB Genres
        
        # ä½¿ç”¨å·²ç¡®å®šçš„å­åˆ†ç±»ï¼ˆanalyze_and_classify å·²è®¾ç½®ï¼‰
        sub_category = cls.sub_category
        
        # è·å– TMDB è¯¦æƒ…ï¼ˆç”¨äºè·å–æ­£ç¡®çš„æ ‡é¢˜ï¼‰
        if series_type == MediaType.TV:
            tmdb_info = tmdb.get_tv_details(tmdb_id)
        else:
            tmdb_info = tmdb.get_movie_details(tmdb_id)
        
        if tmdb_info:
            if effective_language == "en":
                title = tmdb_info.title or tmdb_info.title_zh or series_name
            else:
                title = tmdb_info.title_zh or tmdb_info.title or series_name
            year = tmdb_info.year or year
            # å¦‚æœ classification æ²¡æœ‰ genresï¼Œä» TMDB è·å–
            if not genres and tmdb_info.genres:
                genres = tmdb_info.genres
                sub_category = determine_subcategory(genres)
        else:
            title = series_name
        
        # è·å–å­åˆ†ç±»æ˜¾ç¤ºåç§°
        from backend.agents.models import get_subcategory_name
        sub_name = get_subcategory_name(sub_category, series_type, effective_language)
        
        output += f"### ğŸ“º {title} (TMDB:{tmdb_id}) - {sub_name}\n\n"
        
        if series_type == MediaType.TV:
            # TV ç³»åˆ—ï¼šæŒ‰å­£ç”Ÿæˆ
            series_folder = format_series_folder(title, year)
            
            # ä½¿ç”¨ target_path + è‡ªåŠ¨å­åˆ†ç±»
            category_path = get_target_path(target_path, MediaType.TV, sub_category, effective_language)
            base_folder = f"{category_path}/{series_folder}"
            
            total_subtitle_count = 0
            for season_num in sorted(cls.seasons.keys()):
                files = cls.seasons[season_num]  # List[ClassifiedFile]
                season_folder = format_season_folder(season_num)
                season_subtitle_count = 0
                
                for cf in files:
                    episode = cf.episode
                    if episode <= 0:
                        continue
                    
                    # è§†é¢‘ STRM
                    strm_name = format_strm_episode_name(title, season_num, episode)
                    strm_path = f"{base_folder}/{season_folder}/{strm_name}"
                    strm_content = _generate_strm_content(storage_config, cf.path)
                    all_strm_files.append((strm_path, strm_content))
                    
                    # ğŸ†• æ”¶é›†å­—å¹•ä»»åŠ¡ï¼ˆä¸åœ¨æ­¤å¤„è¯»å–å†…å®¹ï¼‰
                    if cf.subtitles:
                        # ğŸ”¥ å…ˆç”Ÿæˆé»˜è®¤å­—å¹•ä»»åŠ¡ï¼ˆæ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©ï¼‰
                        default_sub = _select_default_subtitle(cf.subtitles)
                        if default_sub:
                            default_sub_name = _format_subtitle_name(title, season_num, episode, default_sub, is_default=True)
                            default_sub_path = f"{base_folder}/{season_folder}/{default_sub_name}"
                            all_subtitle_tasks.append(SubtitleTask(
                                source_path=default_sub.path,
                                target_path=default_sub_path,
                                is_default=True
                            ))
                            season_subtitle_count += 1
                        
                        # ğŸ”¥ å†æ”¶é›†æ‰€æœ‰å¸¦è¯­è¨€æ ‡è¯†çš„å­—å¹•ä»»åŠ¡
                        for sub in cf.subtitles:
                            sub_name = _format_subtitle_name(title, season_num, episode, sub, is_default=False)
                            sub_path = f"{base_folder}/{season_folder}/{sub_name}"
                            all_subtitle_tasks.append(SubtitleTask(
                                source_path=sub.path,
                                target_path=sub_path,
                                is_default=False
                            ))
                            season_subtitle_count += 1
                
                total_subtitle_count += season_subtitle_count
                output += f"- S{season_num:02d}: {len(files)} ä¸ªæ–‡ä»¶"
                if season_subtitle_count > 0:
                    output += f" (+{season_subtitle_count} å­—å¹•)"
                output += "\n"
        
        else:
            # ç”µå½±ï¼šç›´æ¥ç”Ÿæˆ
            files = cls.files  # List[ClassifiedFile]
            movie_folder = format_movie_folder(title, year)
            strm_name = format_strm_movie_name(title, year)
            
            # ä½¿ç”¨ target_path + è‡ªåŠ¨å­åˆ†ç±»
            category_path = get_target_path(target_path, MediaType.MOVIE, sub_category, effective_language)
            base_folder = f"{category_path}/{movie_folder}"
            
            movie_subtitle_count = 0
            for cf in files:
                strm_path = f"{base_folder}/{strm_name}"
                strm_content = _generate_strm_content(storage_config, cf.path)
                all_strm_files.append((strm_path, strm_content))
                
                # ğŸ†• æ”¶é›†å­—å¹•ä»»åŠ¡ï¼ˆä¸åœ¨æ­¤å¤„è¯»å–å†…å®¹ï¼‰
                if cf.subtitles:
                    # ğŸ”¥ å…ˆç”Ÿæˆé»˜è®¤å­—å¹•ä»»åŠ¡ï¼ˆæ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©ï¼‰
                    default_sub = _select_default_subtitle(cf.subtitles)
                    if default_sub:
                        default_sub_name = _format_movie_subtitle_name(title, year, default_sub, is_default=True)
                        default_sub_path = f"{base_folder}/{default_sub_name}"
                        all_subtitle_tasks.append(SubtitleTask(
                            source_path=default_sub.path,
                            target_path=default_sub_path,
                            is_default=True
                        ))
                        movie_subtitle_count += 1
                    
                    # ğŸ”¥ å†æ”¶é›†æ‰€æœ‰å¸¦è¯­è¨€æ ‡è¯†çš„å­—å¹•ä»»åŠ¡
                    for sub in cf.subtitles:
                        sub_name = _format_movie_subtitle_name(title, year, sub, is_default=False)
                        sub_path = f"{base_folder}/{sub_name}"
                        all_subtitle_tasks.append(SubtitleTask(
                            source_path=sub.path,
                            target_path=sub_path,
                            is_default=False
                        ))
                        movie_subtitle_count += 1
            
            output += f"- {len(files)} ä¸ªæ–‡ä»¶"
            if movie_subtitle_count > 0:
                output += f" (+{movie_subtitle_count} å­—å¹•)"
            output += "\n"
        
        output += "\n"
    
    total_strm = len(all_strm_files)
    total_subtitle = len(all_subtitle_tasks)
    total_files = total_strm + total_subtitle
    output += f"---\n**æ€»è®¡: {total_strm} ä¸ª STRM æ–‡ä»¶ + {total_subtitle} ä¸ªå­—å¹•æ–‡ä»¶**\n\n"
    
    # æ ¹æ®è¾“å‡ºæ ¼å¼å¤„ç†
    if output_format == "list":
        output += "### ğŸ“‹ æ–‡ä»¶åˆ—è¡¨ï¼ˆé¢„è§ˆï¼‰\n\n"
        for path, _ in all_strm_files[:20]:
            output += f"- {path}\n"
        if total_strm > 20:
            output += f"- ... è¿˜æœ‰ {total_strm - 20} ä¸ª STRM\n"
        if total_subtitle > 0:
            output += f"\n**å­—å¹•æ–‡ä»¶**: {total_subtitle} ä¸ª\n"
            for task in all_subtitle_tasks[:10]:
                output += f"- {task.target_path}\n"
            if total_subtitle > 10:
                output += f"- ... è¿˜æœ‰ {total_subtitle - 10} ä¸ªå­—å¹•\n"
        return make_tool_response(output)
    
    elif output_format == "zip":
        output += "### ğŸ“¦ ç”Ÿæˆ ZIP æ–‡ä»¶\n\n"
        
        # ğŸ”¥ ZIP æ¨¡å¼éœ€è¦å…ˆä¸‹è½½å­—å¹•å†…å®¹
        output += "â³ æ­£åœ¨ä¸‹è½½å­—å¹•æ–‡ä»¶...\n"
        all_subtitle_files = []
        for task in all_subtitle_tasks:
            content = _read_subtitle_content(source_service, task.source_path)
            if content:
                all_subtitle_files.append((task.target_path, content))
        
        # åˆå¹¶ STRM å’Œå­—å¹•æ–‡ä»¶
        all_files = all_strm_files + all_subtitle_files
        
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            for path, content in all_files:
                zf.writestr(path, content)
        
        zip_buffer.seek(0)
        zip_size = len(zip_buffer.getvalue())
        
        output += f"âœ… ZIP ç”Ÿæˆå®Œæˆ\n"
        output += f"- å¤§å°: {zip_size / 1024:.1f} KB\n"
        output += f"- æ–‡ä»¶æ•°: {len(all_files)}\n\n"
        output += "**æ³¨æ„**: ZIP æ–‡ä»¶å·²åœ¨å†…å­˜ä¸­ç”Ÿæˆï¼Œä½† Agent æ— æ³•ç›´æ¥å‘é€æ–‡ä»¶ã€‚\n"
        output += "è¯·ä½¿ç”¨ webdav æ¨¡å¼ç›´æ¥ä¸Šä¼ åˆ°ç›®æ ‡å­˜å‚¨ã€‚\n"
        
        return make_tool_response(output)
    
    elif output_format == "webdav":
        output += "### ğŸ“¤ ä¸Šä¼ åˆ°ç›®æ ‡å­˜å‚¨\n\n"
        
        # ä» services.py è·å–æœåŠ¡å®ä¾‹
        thread_id = "default"  # åœ¨ InjectedState æ¨¡å¼ä¸‹ï¼Œthread_id éœ€è¦ä» config è·å–
        # ä½†è¿™é‡Œæˆ‘ä»¬ç›´æ¥åˆ›å»ºæœåŠ¡å®ä¾‹ï¼Œå› ä¸º strm_target æ˜¯ä¸´æ—¶çš„
        target_service = create_storage_service_sync(
            url=strm_target_config.get("url", ""),
            username=strm_target_config.get("username", ""),
            password=strm_target_config.get("password", ""),
            base_path="/",
        )
        
        upload_delay = user_config.get("upload_delay", 0)  # ğŸ”¥ ä»ç”¨æˆ·é…ç½®è¯»å–
        
        # ğŸ”¥ å¦‚æœè®¾ç½®äº† upload_delayï¼Œä½¿ç”¨ä¸²è¡Œä¸Šä¼ ï¼ˆå¸¦å»¶è¿Ÿï¼‰
        if upload_delay > 0:
            output += f"â±ï¸ ä½¿ç”¨ä¸²è¡Œä¸Šä¼  (å»¶è¿Ÿ: {upload_delay}s/æ–‡ä»¶)\n"
        else:
            output += f"âš¡ ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œä¸Šä¼  (å¹¶å‘: {UPLOAD_CONCURRENCY})\n"
            output += f"ğŸ†• å­—å¹•å¤„ç†: ä¸‹è½½+ä¸Šä¼ å°è£…ä¸ºå•ä¸ªå¹¶å‘ä»»åŠ¡\n"
        output += f"- æœåŠ¡ç±»å‹: {target_service.service_type}\n"
        output += f"- è¾“å‡ºè·¯å¾„: {target_path}\n\n"
        
        start_time = time.perf_counter()
        strm_success = 0
        strm_error = 0
        sub_success = 0
        sub_error = 0
        failed_paths = []
        
        try:
            if upload_delay > 0:
                # ğŸ”¥ ä¸²è¡Œä¸Šä¼ ï¼ˆå¸¦å»¶è¿Ÿï¼‰- STRM å’Œå­—å¹•åˆ†å¼€å¤„ç†
                import time as time_module
                
                # 1. å…ˆä¸Šä¼  STRM æ–‡ä»¶
                output += "ğŸ“¤ ä¸Šä¼  STRM æ–‡ä»¶...\n"
                for i, (path, content) in enumerate(all_strm_files):
                    if i > 0:
                        time_module.sleep(upload_delay)
                    try:
                        if target_service.put_file_content(path, content):
                            strm_success += 1
                        else:
                            strm_error += 1
                            failed_paths.append(path)
                    except Exception as e:
                        strm_error += 1
                        failed_paths.append(path)
                        logger.warning(f"ä¸Šä¼  STRM å¤±è´¥ {path}: {e}")
                
                # 2. å†å¤„ç†å­—å¹•ï¼ˆä¸²è¡Œï¼šä¸‹è½½+ä¸Šä¼ ï¼‰
                output += "ğŸ“ å¤„ç†å­—å¹•æ–‡ä»¶...\n"
                for i, task in enumerate(all_subtitle_tasks):
                    if i > 0:
                        time_module.sleep(upload_delay)
                    try:
                        # ä¸‹è½½å­—å¹•å†…å®¹
                        content = _read_subtitle_content(source_service, task.source_path)
                        if content:
                            # ä¸Šä¼ åˆ°ç›®æ ‡
                            if target_service.put_file_content(task.target_path, content):
                                sub_success += 1
                            else:
                                sub_error += 1
                                failed_paths.append(task.target_path)
                        else:
                            sub_error += 1
                            failed_paths.append(task.target_path)
                    except Exception as e:
                        sub_error += 1
                        failed_paths.append(task.target_path)
                        logger.warning(f"å¤„ç†å­—å¹•å¤±è´¥ {task.source_path}: {e}")
            else:
                # ğŸ†• å¼‚æ­¥å¹¶è¡Œä¸Šä¼  + åˆ·æ–°
                # ğŸ”¥ æ”¶é›†éœ€è¦åˆ·æ–°çš„ç›®å½•ï¼ˆåœ¨ä¸Šä¼ å‰æ”¶é›†ï¼‰
                dirs_to_refresh = set()
                for path, _ in all_strm_files:
                    dir_path = os.path.dirname(path)
                    if dir_path:
                        dirs_to_refresh.add(dir_path)
                for task in all_subtitle_tasks:
                    dir_path = os.path.dirname(task.target_path)
                    if dir_path:
                        dirs_to_refresh.add(dir_path)
                
                # ğŸ”¥ å°†ä¸Šä¼ å’Œåˆ·æ–°æ”¾åœ¨åŒä¸€ä¸ª async å‡½æ•°ä¸­ï¼Œé¿å…äº‹ä»¶å¾ªç¯å…³é—­é—®é¢˜
                async def _upload_and_refresh_async():
                    nonlocal strm_success, strm_error, sub_success, sub_error, failed_paths
                    
                    # 1. å¹¶è¡Œä¸Šä¼  STRM æ–‡ä»¶
                    logger.info(f"å¼€å§‹å¹¶è¡Œä¸Šä¼  {len(all_strm_files)} ä¸ª STRM æ–‡ä»¶...")
                    s_success, s_error, s_failed = await target_service.upload_files_batch_async(
                        all_strm_files, concurrency=UPLOAD_CONCURRENCY
                    )
                    strm_success = s_success
                    strm_error = s_error
                    failed_paths.extend(s_failed)
                    
                    # 2. å¹¶è¡Œå¤„ç†å­—å¹•ï¼ˆä¸‹è½½+ä¸Šä¼ å°è£…ä¸ºå•ä¸ªä»»åŠ¡ï¼‰
                    _failed_upload_details = []  # ğŸ†• æ”¶é›†è¯¦ç»†å¤±è´¥ä¿¡æ¯
                    if all_subtitle_tasks:
                        logger.info(f"å¼€å§‹å¹¶è¡Œå¤„ç† {len(all_subtitle_tasks)} ä¸ªå­—å¹•ä»»åŠ¡...")
                        sub_s, sub_e, sub_f, sub_details = await _process_subtitles_batch_async(
                            all_subtitle_tasks,
                            source_service,
                            target_service,
                            concurrency=SUBTITLE_UPLOAD_CONCURRENCY
                        )
                        sub_success = sub_s
                        sub_error = sub_e
                        failed_paths.extend(sub_f)
                        _failed_upload_details.extend(sub_details)  # ğŸ†• æ”¶é›†è¯¦ç»†å¤±è´¥ä¿¡æ¯
                    
                    # 3. ğŸ”¥ åˆ·æ–°ç›®å½•ç¼“å­˜ï¼ˆåœ¨åŒä¸€ä¸ªäº‹ä»¶å¾ªç¯ä¸­ï¼‰
                    refresh_results = {}
                    if dirs_to_refresh and hasattr(target_service, 'refresh_directories_batch_async'):
                        logger.info(f"åˆ·æ–°ç›®å½•ç¼“å­˜: {len(dirs_to_refresh)} ä¸ªç›®å½•")
                        refresh_results = await target_service.refresh_directories_batch_async(
                            list(dirs_to_refresh), concurrency=4
                        )
                    
                    return refresh_results, _failed_upload_details  # ğŸ†• è¿”å›å¤±è´¥è¯¦æƒ…
                
                refresh_results, failed_upload_details = asyncio.run(_upload_and_refresh_async())
            
            elapsed = time.perf_counter() - start_time
            total_success = strm_success + sub_success
            total_error = strm_error + sub_error
            
            output += f"âœ… ä¸Šä¼ å®Œæˆ ({elapsed:.1f}s)\n"
            output += f"- STRM: {strm_success} æˆåŠŸ"
            if strm_error > 0:
                output += f", {strm_error} å¤±è´¥"
            output += "\n"
            output += f"- å­—å¹•: {sub_success} æˆåŠŸ"
            if sub_error > 0:
                output += f", {sub_error} å¤±è´¥"
            output += "\n"
            if total_error > 0:
                logger.warning(f"ä¸Šä¼ å¤±è´¥çš„æ–‡ä»¶ ({len(failed_paths)} ä¸ª): {failed_paths[:10]}...")
                output += f"- å¤±è´¥æ–‡ä»¶ç¤ºä¾‹: {failed_paths[:3]}\n"
            if elapsed > 0:
                output += f"- å¹³å‡é€Ÿåº¦: {total_success / elapsed:.1f} æ–‡ä»¶/ç§’\n"
            
            # è¾“å‡ºåˆ·æ–°ç»“æœ
            if refresh_results:
                refresh_success = sum(1 for v in refresh_results.values() if v)
                output += f"ğŸ”„ åˆ·æ–°ç›®å½•: {refresh_success}/{len(refresh_results)} æˆåŠŸ\n"
            
        except Exception as e:
            output += f"âŒ ä¸Šä¼ å¤±è´¥: {e}\n"
            logger.exception("ä¸Šä¼ å¤±è´¥")
        
        # æ¸…é™¤å·²å¤„ç†çš„åˆ†ç±»æ•°æ®ï¼ˆé€šè¿‡è¿”å›ç©º classificationsï¼‰
        total_success = strm_success + sub_success
        total_error = strm_error + sub_error
        
        # ğŸ†• æ„å»º state_update
        state_update = {
            "classifications": [],  # æ¸…ç©ºåˆ†ç±»æ•°æ®
            "strm_progress": {
                "total": total_files,
                "success": total_success,
                "error": total_error,
                "status": "completed",
            }
        }
        
        # ğŸ†• å¦‚æœæœ‰å¤±è´¥çš„ä¸Šä¼ ï¼Œä¿å­˜åˆ° state ä¾›é‡è¯•
        try:
            if failed_upload_details:
                state_update["failed_uploads"] = failed_upload_details
                output += f"\nğŸ’¡ **æç¤º**: æœ‰ {len(failed_upload_details)} ä¸ªå­—å¹•æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œå¯ä»¥ä½¿ç”¨ `retry_failed_uploads` é‡è¯•\n"
        except NameError:
            pass  # åŒæ­¥æ¨¡å¼ä¸‹æ²¡æœ‰ failed_upload_details
        
        return make_tool_response(output, state_update=state_update)
    
    else:
        return make_tool_response(f"âŒ æœªçŸ¥çš„è¾“å‡ºæ ¼å¼: {output_format}")


@tool
def retry_failed_uploads(
    state: Annotated[dict, InjectedState] = None,
) -> str:
    """
    ğŸ”„ é‡è¯•å¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡
    
    ä» state.failed_uploads è¯»å–å¤±è´¥çš„ä»»åŠ¡å¹¶é‡è¯•ã€‚
    ä½¿ç”¨åŒæ­¥æ–¹æ³•é¿å…äº‹ä»¶å¾ªç¯é—®é¢˜ã€‚
    
    Returns:
        é‡è¯•ç»“æœæ‘˜è¦
    """
    logger.info("ğŸ”„ retry_failed_uploads è¢«è°ƒç”¨")
    
    # è·å–å¤±è´¥çš„ä»»åŠ¡åˆ—è¡¨
    failed_uploads = state.get("failed_uploads", []) if state else []
    
    if not failed_uploads:
        return make_tool_response("âœ… æ²¡æœ‰éœ€è¦é‡è¯•çš„å¤±è´¥ä»»åŠ¡")
    
    # è·å–å­˜å‚¨æœåŠ¡
    source_service = get_storage_service(state)
    target_service = get_strm_target_service(state)
    
    if not source_service or not target_service:
        return make_tool_response("âŒ è¯·å…ˆè¿æ¥æºå­˜å‚¨å’Œç›®æ ‡å­˜å‚¨")
    
    output = f"## ğŸ”„ é‡è¯•å¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡\n\n"
    output += f"å…±æœ‰ {len(failed_uploads)} ä¸ªä»»åŠ¡éœ€è¦é‡è¯•\n\n"
    
    # ğŸ”¥ ä½¿ç”¨åŒæ­¥æ–¹æ³•é€ä¸ªé‡è¯•ï¼Œé¿å…äº‹ä»¶å¾ªç¯é—®é¢˜
    success_count = 0
    error_count = 0
    still_failed = []
    
    for item in failed_uploads:
        if item.get("type") != "subtitle":
            continue
            
        source_path = item["source_path"]
        target_path = item["target_path"]
        
        try:
            # 1. åŒæ­¥ä¸‹è½½å­—å¹•å†…å®¹
            logger.info(f"ğŸ“¥ é‡è¯•ä¸‹è½½: {os.path.basename(source_path)}")
            content = source_service.get_file_content(source_path)
            
            if not content:
                error_msg = "ä¸‹è½½å¤±è´¥ï¼ˆè¿”å›ç©ºå†…å®¹ï¼‰"
                logger.warning(f"âŒ {error_msg}: {source_path}")
                error_count += 1
                still_failed.append({
                    "source_path": source_path,
                    "target_path": target_path,
                    "type": "subtitle",
                    "error": error_msg
                })
                continue
            
            # 2. åŒæ­¥ä¸Šä¼ åˆ°ç›®æ ‡
            logger.info(f"ğŸ“¤ é‡è¯•ä¸Šä¼ : {os.path.basename(target_path)}")
            success = target_service.put_file_content(target_path, content)
            
            if success:
                logger.info(f"âœ… é‡è¯•æˆåŠŸ: {os.path.basename(source_path)}")
                success_count += 1
            else:
                error_msg = "ä¸Šä¼ å¤±è´¥ï¼ˆAPIè¿”å›å¤±è´¥ï¼‰"
                logger.warning(f"âŒ {error_msg}: {target_path}")
                error_count += 1
                still_failed.append({
                    "source_path": source_path,
                    "target_path": target_path,
                    "type": "subtitle",
                    "error": error_msg
                })
                
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ é‡è¯•å¼‚å¸¸ {source_path}: {e}")
            error_count += 1
            still_failed.append({
                "source_path": source_path,
                "target_path": target_path,
                "type": "subtitle",
                "error": error_msg
            })
    
    output += f"âœ… é‡è¯•å®Œæˆ\n"
    output += f"- æˆåŠŸ: {success_count}\n"
    output += f"- ä»ç„¶å¤±è´¥: {error_count}\n"
    
    if still_failed:
        output += f"\n### âš ï¸ ä»ç„¶å¤±è´¥çš„æ–‡ä»¶\n"
        for item in still_failed[:5]:
            output += f"- `{os.path.basename(item['source_path'])}`: {item['error']}\n"
        if len(still_failed) > 5:
            output += f"- ... è¿˜æœ‰ {len(still_failed) - 5} ä¸ª\n"
    
    # æ›´æ–° state
    state_update = {}
    if still_failed:
        state_update["failed_uploads"] = still_failed
        output += f"\nğŸ’¡ å¯ä»¥å†æ¬¡ä½¿ç”¨ `retry_failed_uploads` é‡è¯•\n"
    else:
        state_update["failed_uploads"] = []  # æ¸…ç©º
        output += f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²æˆåŠŸå®Œæˆï¼\n"
    
    return make_tool_response(output, state_update=state_update)
