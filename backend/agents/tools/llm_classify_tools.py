"""
LLM åˆ†ç±»å·¥å…·

ğŸ”¥ æ ¸å¿ƒè®¾è®¡ï¼šè®© LLM åšæ‰€æœ‰åˆ¤æ–­ï¼Œä»£ç åªæ‰§è¡Œ

ä¸å†ç”¨ä»£ç åšä»»ä½•ã€ŒåŒ¹é…ã€æˆ–ã€Œåˆ¤æ–­ã€ï¼Œæ‰€æœ‰åˆ†ç±»å†³ç­–ç”± LLM å®Œæˆã€‚
"""

import json
import logging
from typing import Dict, Any, List, Annotated
from langchain.tools import tool
from langgraph.prebuilt import InjectedState

from backend.agents.tool_response import make_tool_response
from backend.services.tmdb_service import get_tmdb_service
import re
from backend.agents.models import (
    ScannedFile,
    Classification,
    ClassifiedFile,
    SubtitleFile,
    MediaType,
    determine_subcategory,
    ClassificationResultItem,
    get_or_build_mapping,
    LLMClassifyFileItem,
    LLMClassificationResult,
)
from backend.agents.models.output import SeasonInfo

logger = logging.getLogger(__name__)


def _parse_scanned_files(scanned_files_data: List[Any]) -> List[ScannedFile]:
    """è§£ææ‰«ææ–‡ä»¶æ•°æ®"""
    files = []
    for f in scanned_files_data:
        if isinstance(f, dict):
            files.append(ScannedFile.model_validate(f))
        elif isinstance(f, ScannedFile):
            files.append(f)
    return files


def _get_base_name(filename: str) -> str:
    """æå–æ–‡ä»¶ä¸»åç§°ï¼ˆå»æ‰è¯­è¨€æ ‡è¯†å’Œæ‰©å±•åï¼‰
    
    Examples:
        [001].chs.srt â†’ [001]
        [001].mkv â†’ [001]
        Movie.2020.chs.ass â†’ Movie.2020
        [001].scjp.ass â†’ [001]
        [001].tcjp.ass â†’ [001]
    """
    # ç§»é™¤æ‰©å±•å
    name = re.sub(r'\.(srt|ass|ssa|sub|mkv|mp4|avi|wmv|flv|mov)$', '', filename, flags=re.IGNORECASE)
    # ç§»é™¤è¯­è¨€æ ‡è¯†ï¼ˆåŒ…æ‹¬å¤åˆè¯­è¨€æ ‡è¯†å¦‚ scjp, tcjpï¼‰
    name = re.sub(r'\.(chs|cht|chi|eng|jpn|jap|kor|und|sc|tc|scjp|tcjp|chtjp|chsjp)$', '', name, flags=re.IGNORECASE)
    return name


def _build_file_list_text(files: List[ScannedFile], max_files: int = 200) -> str:
    """æ„å»ºæ–‡ä»¶åˆ—è¡¨æ–‡æœ¬ï¼ˆç”¨äº LLM è¾“å…¥ï¼‰"""
    video_files = [f for f in files if f.type == 'video']
    
    lines = []
    for i, f in enumerate(video_files[:max_files], 1):
        # ç®€åŒ–æ–‡ä»¶ä¿¡æ¯ï¼šåªä¿ç•™æ–‡ä»¶åå’Œç›®å½•
        lines.append(f"{i}. {f.name}")
        if f.directory:
            lines.append(f"   ç›®å½•: {f.directory}")
    
    if len(video_files) > max_files:
        lines.append(f"... è¿˜æœ‰ {len(video_files) - max_files} ä¸ªæ–‡ä»¶")
    
    return "\n".join(lines)


def _build_tmdb_info_text(tmdb_ids: List[int]) -> str:
    """æ„å»º TMDB ä¿¡æ¯æ–‡æœ¬ï¼ˆç”¨äº LLM è¾“å…¥ï¼‰"""
    tmdb = get_tmdb_service()
    lines = []
    
    for tmdb_id in tmdb_ids:
        mapping = get_or_build_mapping(tmdb_id, tmdb)
        if not mapping:
            continue
        
        lines.append(f"### {mapping.title} (TMDB: {tmdb_id})")
        
        for season_info in mapping.get_all_seasons_info():
            s = season_info['season']
            ep_count = season_info['episode_count']
            ep_start = season_info['tmdb_ep_start']
            ep_end = season_info['tmdb_ep_end']
            lines.append(f"- ç¬¬{s}å­£: {ep_count}é›† (E{ep_start:02d}-E{ep_end:02d})")
        
        lines.append("")
    
    return "\n".join(lines)


@tool
def prepare_llm_classification(
    tmdb_ids_json: str,
    state: Annotated[dict, InjectedState] = None,
) -> str:
    """
    ğŸ”¥ å‡†å¤‡ LLM åˆ†ç±»æ•°æ®
    
    æ”¶é›†æ–‡ä»¶åˆ—è¡¨å’Œ TMDB ä¿¡æ¯ï¼Œç”Ÿæˆç»“æ„åŒ–æ•°æ®ä¾› LLM åˆ†ç±»ä½¿ç”¨ã€‚
    
    Args:
        tmdb_ids_json: TMDB ID åˆ—è¡¨çš„ JSONï¼Œå¦‚ "[30977, 46260]"
    
    Returns:
        ç»“æ„åŒ–çš„åˆ†ç±»æ•°æ®ï¼ŒLLM å¯ä»¥ç›´æ¥ä½¿ç”¨
    """
    logger.info("ğŸ”¥ prepare_llm_classification è¢«è°ƒç”¨")
    
    # ä» State è¯»å–æ•°æ®
    scanned_files_data = state.get("scanned_files", []) if state else []
    
    if not scanned_files_data:
        return make_tool_response("âŒ è¯·å…ˆä½¿ç”¨ scan_media_files æ‰«ææ–‡ä»¶")
    
    # è§£æ TMDB IDs
    try:
        tmdb_ids = json.loads(tmdb_ids_json) if tmdb_ids_json else []
        if isinstance(tmdb_ids, int):
            tmdb_ids = [tmdb_ids]
    except json.JSONDecodeError:
        return make_tool_response("âŒ tmdb_ids_json æ ¼å¼é”™è¯¯")
    
    if not tmdb_ids:
        return make_tool_response("âŒ è¯·æä¾› TMDB ID åˆ—è¡¨")
    
    # è§£ææ–‡ä»¶
    scanned_files = _parse_scanned_files(scanned_files_data)
    video_files = [f for f in scanned_files if f.type == 'video']
    
    if not video_files:
        return make_tool_response("âŒ æ‰«æç»“æœä¸­æ²¡æœ‰è§†é¢‘æ–‡ä»¶")
    
    # æ„å»ºæ–‡ä»¶åˆ—è¡¨
    file_list_text = _build_file_list_text(scanned_files)
    
    # æ„å»º TMDB ä¿¡æ¯
    tmdb_info_text = _build_tmdb_info_text(tmdb_ids)
    
    # ç”Ÿæˆåˆ†ç±»æç¤ºï¼ˆä½¿ç”¨ CSV æ ¼å¼ï¼Œæ›´ç´§å‡‘ï¼‰
    output = f"""# ğŸ¬ LLM åˆ†ç±»æ•°æ®

## æ–‡ä»¶åˆ—è¡¨ ({len(video_files)} ä¸ªè§†é¢‘)

{file_list_text}

## TMDB ä¿¡æ¯

{tmdb_info_text}

---

## ğŸ”¥ è¯·ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ†ç±»

æ ¹æ®æ–‡ä»¶åå’Œ TMDB ä¿¡æ¯ï¼Œä¸ºæ¯ä¸ªæ–‡ä»¶ç¡®å®šæ­£ç¡®çš„åˆ†ç±»ã€‚

**è¾“å‡ºæ ¼å¼ï¼ˆCSVï¼‰**:
```csv
file_index,tmdb_id,type,season,episode
1,30977,0,1,1
2,30977,0,1,2
3,30977,0,1,3
28,120811,1,0,0
29,186810,1,0,0
```

**å­—æ®µè¯´æ˜**:
- `file_index`: æ–‡ä»¶åºå·
- `tmdb_id`: TMDB ID
- `type`: åª’ä½“ç±»å‹ï¼Œ`0`=TVå‰§é›†ï¼Œ`1`=ç”µå½±
- `season`: å­£å·ï¼ˆç”µå½±ä¸º 0ï¼‰
- `episode`: é›†å·ï¼ˆç”µå½±ä¸º 0ï¼‰

**æ— æ³•åˆ†ç±»çš„æ–‡ä»¶**ï¼ˆå¯é€‰ï¼‰:
```csv
unmatched:file_index,reason
82,éåª’ä½“æ–‡ä»¶
```

**åˆ†ç±»è§„åˆ™**:
1. æ ¹æ®æ–‡ä»¶åä¸­çš„é›†æ•°ï¼ˆå¦‚ [01]ã€EP01ã€ç¬¬01è¯ï¼‰ç¡®å®š episode
2. æ ¹æ®ç›®å½•åæˆ–æ–‡ä»¶åä¸­çš„å­£æ ‡è¯†ç¡®å®š season:
   - æ— æ ‡è¯† / ç¬¬ä¸€å­£ / S1 â†’ season 1
   - S / ç¬¬äºŒå­£ / S2 / !! â†’ season 2
   - T / ç¬¬ä¸‰å­£ / S3 / !!! â†’ season 3
3. **ç”µå½±/å‰§åœºç‰ˆ/æ¼”å”±ä¼š**ï¼štype=1, season=0, episode=0
4. å¦‚æœæ— æ³•ç¡®å®šï¼Œæ”¾å…¥ unmatched éƒ¨åˆ†

è¯·ç›´æ¥è¾“å‡º CSV æ ¼å¼ï¼Œä¸è¦å…¶ä»–è¯´æ˜ã€‚
"""
    
    # ä¿å­˜æ–‡ä»¶åˆ—è¡¨åˆ° stateï¼Œä¾›åç»­ä½¿ç”¨
    # ğŸ”¥ ä½¿ç”¨ Pydantic æ¨¡å‹ï¼Œç„¶å model_dump() åºåˆ—åŒ–
    file_list_for_state = [
        LLMClassifyFileItem(
            index=i,
            name=f.name,
            path=f.path,
            directory=f.directory or ""
        ).model_dump()
        for i, f in enumerate(video_files, 1)
    ]
    
    return make_tool_response(
        output,
        state_update={
            "llm_classify_files": file_list_for_state,
            "llm_classify_tmdb_ids": tmdb_ids,
        }
    )


def _parse_csv_classification(csv_data: str) -> tuple:
    """
    è§£æ CSV æ ¼å¼çš„åˆ†ç±»ç»“æœ
    
    æ ¼å¼:
    file_index,tmdb_id,type,season,episode
    1,30977,0,1,1      # type=0 è¡¨ç¤º TV
    28,120811,1,0,0    # type=1 è¡¨ç¤º Movie
    
    unmatched:file_index,reason
    82,éåª’ä½“æ–‡ä»¶
    
    Returns:
        (classifications, unmatched)
    """
    classifications = []
    unmatched = []
    
    lines = csv_data.strip().split('\n')
    in_unmatched = False
    
    for line in lines:
        line = line.strip()
        
        # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
        if not line or line.startswith('#'):
            continue
        
        # è·³è¿‡è¡¨å¤´
        if line.startswith('file_index,') or line.startswith('unmatched:file_index'):
            if 'unmatched' in line.lower():
                in_unmatched = True
            continue
        
        # æ£€æµ‹ unmatched éƒ¨åˆ†å¼€å§‹
        if line.lower().startswith('unmatched'):
            in_unmatched = True
            continue
        
        # è·³è¿‡ markdown ä»£ç å—æ ‡è®°
        if line.startswith('```'):
            continue
        
        parts = line.split(',')
        
        if in_unmatched:
            # è§£æ unmatched: file_index,reason
            if len(parts) >= 1:
                try:
                    file_index = int(parts[0].strip())
                    reason = parts[1].strip() if len(parts) > 1 else "æœªçŸ¥åŸå› "
                    unmatched.append({
                        'file_index': file_index,
                        'reason': reason
                    })
                except ValueError:
                    continue
        else:
            # æ ¼å¼: file_index,tmdb_id,type,season,episode (5 åˆ—)
            if len(parts) >= 5:
                try:
                    file_index = int(parts[0].strip())
                    tmdb_id = int(parts[1].strip())
                    type_val = parts[2].strip()
                    season = int(parts[3].strip())
                    episode = int(parts[4].strip())
                    
                    # type: 0=TV, 1=Movie
                    media_type = 'movie' if type_val == '1' else 'tv'
                    
                    classifications.append({
                        'file_index': file_index,
                        'tmdb_id': tmdb_id,
                        'media_type': media_type,
                        'season': season,
                        'episode': episode
                    })
                except ValueError:
                    continue
    
    return classifications, unmatched


@tool
def generate_classification(
    classifications_csv: str,
    state: Annotated[dict, InjectedState] = None,
) -> str:
    """
    ğŸ”¥ ç”Ÿæˆæœ€ç»ˆåˆ†ç±»ç»“æœ
    
    æ¥æ”¶ LLM ç”Ÿæˆçš„åˆ†ç±» CSVï¼Œè§£æå¹¶ä¿å­˜åˆ° stateã€‚
    è¿”å›åˆ†ç±»é¢„è§ˆä¾›ç”¨æˆ·ç¡®è®¤ã€‚
    
    âš ï¸ æ³¨æ„ï¼šä¸è¦åœ¨å¯¹è¯ä¸­è¾“å‡º CSVï¼Œç›´æ¥ä½œä¸ºå‚æ•°ä¼ é€’ï¼
    
    Args:
        classifications_csv: LLM ç”Ÿæˆçš„åˆ†ç±»ç»“æœ CSV
            æ ¼å¼: file_index,tmdb_id,type,season,episode
            ç¤ºä¾‹: 1,30977,0,1,1
    
    Returns:
        åˆ†ç±»ç»“æœé¢„è§ˆ
    """
    logger.info("ğŸ”¥ generate_classification è¢«è°ƒç”¨")
    
    # è°ƒè¯•æ—¥å¿—
    csv_lines = classifications_csv.strip().split('\n') if classifications_csv else []
    logger.info(f"ğŸ“Š æ”¶åˆ° CSV æ•°æ®: {len(csv_lines)} è¡Œ")
    
    # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å° state çš„æ‰€æœ‰ keys
    if state:
        logger.info(f"ğŸ” state keys: {list(state.keys())}")
        logger.info(f"ğŸ” llm_classify_files å­˜åœ¨: {'llm_classify_files' in state}")
        logger.info(f"ğŸ” llm_classify_tmdb_ids å­˜åœ¨: {'llm_classify_tmdb_ids' in state}")
    else:
        logger.warning("ğŸ” state ä¸º None")
    
    # ä» State è¯»å–æ•°æ®
    scanned_files_data = state.get("scanned_files", []) if state else []
    file_list = state.get("llm_classify_files", []) if state else []
    tmdb_ids = state.get("llm_classify_tmdb_ids", []) if state else []
    
    logger.info(f"ğŸ” file_list é•¿åº¦: {len(file_list)}, tmdb_ids: {tmdb_ids}")
    
    if not file_list:
        return make_tool_response("âŒ è¯·å…ˆè°ƒç”¨ prepare_llm_classification")
    
    # ğŸ”¥ ä½¿ç”¨ Pydantic éªŒè¯æ–‡ä»¶åˆ—è¡¨
    file_list_validated = [LLMClassifyFileItem.model_validate(f) for f in file_list]
    
    # ğŸ”¥ è§£æ CSV æ ¼å¼çš„åˆ†ç±»ç»“æœ
    try:
        classifications_list, unmatched_list = _parse_csv_classification(classifications_csv)
        logger.info(f"ğŸ” è§£æåˆ° {len(classifications_list)} ä¸ªåˆ†ç±», {len(unmatched_list)} ä¸ªæœªåŒ¹é…")
    except Exception as e:
        return make_tool_response(f"âŒ CSV è§£æå¤±è´¥: {e}")
    
    if not classifications_list:
        return make_tool_response("âŒ åˆ†ç±»ç»“æœä¸ºç©º")
    
    # æ„å»ºæ–‡ä»¶ç´¢å¼•ï¼ˆä½¿ç”¨éªŒè¯åçš„ Pydantic å¯¹è±¡ï¼‰
    file_index_map = {f.index: f for f in file_list_validated}
    
    # è§£æåŸå§‹æ‰«ææ–‡ä»¶ï¼ˆç”¨äºè·å–å­—å¹•ï¼‰
    scanned_files = _parse_scanned_files(scanned_files_data)
    subtitle_files = [f for f in scanned_files if f.type == 'subtitle']
    
    # æ„å»ºå­—å¹•ç´¢å¼•ï¼ˆä½¿ç”¨æ­£ç¡®çš„ base_name æå–å‡½æ•°ï¼‰
    from collections import defaultdict
    subtitle_index = defaultdict(list)
    for sub in subtitle_files:
        base_name = _get_base_name(sub.name)
        subtitle_index[(sub.directory, base_name)].append(sub)
    
    # ğŸ” è°ƒè¯•ï¼šæ‰“å°å­—å¹•ç´¢å¼•çš„ key æ ·æœ¬
    sample_keys = list(subtitle_index.keys())[:5]
    logger.info(f"ğŸ” å­—å¹•ç´¢å¼•æ ·æœ¬ keys: {sample_keys}")
    
    # ğŸ”¥ å…ˆä» CSV åˆ†ç±»ç»“æœä¸­æå–æ¯ä¸ª TMDB ID çš„åª’ä½“ç±»å‹
    tmdb_media_types = {}
    for cls_item in classifications_list:
        tmdb_id = cls_item['tmdb_id']
        media_type_str = cls_item.get('media_type', 'tv')
        # å¦‚æœåŒä¸€ä¸ª TMDB ID æœ‰å¤šä¸ªåˆ†ç±»ï¼Œä»¥ç¬¬ä¸€ä¸ªä¸ºå‡†
        if tmdb_id not in tmdb_media_types:
            tmdb_media_types[tmdb_id] = MediaType.MOVIE if media_type_str == 'movie' else MediaType.TV
    
    # è·å– TMDB ä¿¡æ¯ï¼ˆæ ¹æ® LLM æŒ‡å®šçš„åª’ä½“ç±»å‹ï¼‰
    tmdb = get_tmdb_service()
    tmdb_info_cache = {}
    
    for tmdb_id in tmdb_ids:
        # ğŸ”¥ æ ¹æ® LLM æŒ‡å®šçš„åª’ä½“ç±»å‹è·å–ä¿¡æ¯
        media_type = tmdb_media_types.get(tmdb_id, MediaType.TV)
        
        if media_type == MediaType.MOVIE:
            info = tmdb.get_movie_details(tmdb_id)
        else:
            info = tmdb.get_tv_details(tmdb_id)
        
        if info:
            tmdb_info_cache[tmdb_id] = {
                "name": info.title_zh or info.title or f"TMDB:{tmdb_id}",
                "year": info.year,
                "genres": info.genres or [],
                "media_type": media_type,  # ä½¿ç”¨ LLM æŒ‡å®šçš„åª’ä½“ç±»å‹
            }
            logger.info(f"ğŸ” TMDB {tmdb_id}: name={info.title_zh or info.title}, type={media_type}")
    
    # æ„å»ºåˆ†ç±»ç»“æœ
    classifications: Dict[int, Classification] = {}
    
    # ğŸ”¥ éå† CSV è§£æå‡ºçš„åˆ†ç±»åˆ—è¡¨ï¼ˆdict æ ¼å¼ï¼‰
    for cls_item in classifications_list:
        file_idx = cls_item['file_index']
        tmdb_id = cls_item['tmdb_id']
        season = cls_item['season']
        episode = cls_item['episode']
        
        if file_idx not in file_index_map:
            continue
        
        # ğŸ”¥ file_info æ˜¯ LLMClassifyFileItem (Pydantic)
        file_info = file_index_map[file_idx]
        
        # åˆå§‹åŒ–åˆ†ç±»ç»“æ„
        if tmdb_id not in classifications:
            info = tmdb_info_cache.get(tmdb_id, {})
            genres = info.get("genres", [])
            sub_category = determine_subcategory(genres)
            media_type = info.get("media_type", MediaType.TV)  # ğŸ”¥ ä½¿ç”¨ç¼“å­˜çš„åª’ä½“ç±»å‹
            
            classifications[tmdb_id] = Classification(
                tmdb_id=tmdb_id,
                name=info.get("name", f"TMDB:{tmdb_id}"),
                type=media_type,  # ğŸ”¥ ä½¿ç”¨æ­£ç¡®çš„åª’ä½“ç±»å‹
                year=info.get("year", 0),
                genres=genres,
                sub_category=sub_category,
                seasons={},
                files=[]
            )
        
        # è·å–å­—å¹•ï¼ˆä½¿ç”¨æ­£ç¡®çš„ base_name æå–å‡½æ•°ï¼‰
        file_name = file_info.name
        file_dir = file_info.directory
        base_name = _get_base_name(file_name)
        subs = subtitle_index.get((file_dir, base_name), [])
        
        # ğŸ” è°ƒè¯•ï¼šå¦‚æœæ²¡æœ‰æ‰¾åˆ°å­—å¹•ï¼Œæ‰“å°åŒ¹é…ä¿¡æ¯
        if not subs and file_idx <= 5:
            logger.info(f"ğŸ” æ–‡ä»¶ {file_idx}: name={file_name}, dir={file_dir}, base_name={base_name}")
            logger.info(f"ğŸ” æŸ¥æ‰¾ key: ({file_dir}, {base_name})")
        
        # åˆ›å»ºåˆ†ç±»æ–‡ä»¶
        classified_file = ClassifiedFile(
            path=file_info.path,
            name=file_name,
            episode=episode,
            season=season,
            subtitles=[
                SubtitleFile(path=s.path, name=s.name, language=s.language or "und")
                for s in subs
            ]
        )
        
        # ğŸ”¥ æ ¹æ®åª’ä½“ç±»å‹å†³å®šæ·»åŠ åˆ°å“ªé‡Œ
        if classifications[tmdb_id].type == MediaType.MOVIE or (season == 0 and episode == 0):
            # ç”µå½±ï¼šæ·»åŠ åˆ° files åˆ—è¡¨
            classifications[tmdb_id].files.append(classified_file)
        else:
            # TVï¼šæ·»åŠ åˆ°å¯¹åº”å­£
            if season not in classifications[tmdb_id].seasons:
                classifications[tmdb_id].seasons[season] = []
            classifications[tmdb_id].seasons[season].append(classified_file)
    
    # ç”ŸæˆæŠ¥å‘Š
    output = "# ğŸ“Š åˆ†ç±»ç»“æœ (LLM åˆ†ç±»)\n\n"
    output += f"**å·²åˆ†ç±»**: {len(classifications_list)} ä¸ªæ–‡ä»¶\n\n"
    
    for tmdb_id, cls in classifications.items():
        # ğŸ”¥ æ ¹æ®åª’ä½“ç±»å‹æ˜¾ç¤ºä¸åŒçš„å›¾æ ‡
        icon = "ğŸ¬" if cls.type == MediaType.MOVIE else "ğŸ“º"
        output += f"### {icon} {cls.name} (TMDB:{tmdb_id})\n\n"
        
        if cls.type == MediaType.MOVIE:
            # ç”µå½±ï¼šæ˜¾ç¤ºæ–‡ä»¶æ•°
            total_files = len(cls.files) + sum(len(files) for files in cls.seasons.values())
            output += f"**æ–‡ä»¶æ•°: {total_files}**\n\n"
        else:
            # TVï¼šæ˜¾ç¤ºå­£å’Œé›†æ•°
            output += "| å­£ | æ–‡ä»¶æ•° | é›†æ•°èŒƒå›´ |\n"
            output += "|---|--------|----------|\n"
            
            total_files = 0
            for season_num in sorted(cls.seasons.keys()):
                files = cls.seasons[season_num]
                if files:
                    eps = sorted([f.episode for f in files if f.episode > 0])
                    if eps:
                        output += f"| S{season_num:02d} | {len(files)} | E{eps[0]:02d}-E{eps[-1]:02d} |\n"
                    else:
                        output += f"| S{season_num:02d} | {len(files)} | - |\n"
                    total_files += len(files)
            
            output += f"\n**å°è®¡: {total_files} ä¸ªæ–‡ä»¶**\n\n"
    
    # æœªåŒ¹é…æ–‡ä»¶
    if unmatched_list:
        output += f"## âš ï¸ æœªåŒ¹é…æ–‡ä»¶: {len(unmatched_list)} ä¸ª\n\n"
        for item in unmatched_list[:10]:
            # ğŸ”¥ item æ˜¯ dictï¼ˆä» CSV è§£æï¼‰
            file_idx = item['file_index']
            reason = item.get('reason', 'æœªçŸ¥åŸå› ')
            file_info = file_index_map.get(file_idx)
            file_name = file_info.name if file_info else f'æ–‡ä»¶{file_idx}'
            output += f"- {file_name}: {reason}\n"
        if len(unmatched_list) > 10:
            output += f"- ... è¿˜æœ‰ {len(unmatched_list) - 10} ä¸ª\n"
        output += "\n"
    
    # ä¸‹ä¸€æ­¥æç¤º
    output += "---\n\n"
    output += "## ğŸ¯ ä¸‹ä¸€æ­¥\n\n"
    output += "è¯·é€‰æ‹©æ“ä½œï¼š\n"
    output += "- **æ‰§è¡Œ STRM**: `connect_strm_target` â†’ `generate_strm`\n"
    output += "- **æ‰§è¡Œä¼ ç»Ÿæ•´ç†**: `organize_files`\n"
    output += "- **é‡æ–°åˆ†ç±»**: å‘Šè¯‰æˆ‘éœ€è¦è°ƒæ•´çš„åœ°æ–¹\n"
    
    # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
    def _classification_to_dict(cls: Classification) -> Dict:
        return {
            "tmdb_id": cls.tmdb_id,
            "name": cls.name,
            "type": cls.type.value if hasattr(cls.type, 'value') else str(cls.type),
            "year": cls.year,
            "genres": cls.genres,
            "sub_category": cls.sub_category.value if hasattr(cls.sub_category, 'value') else str(cls.sub_category),
            "seasons": {
                k: [
                    {
                        "path": f.path,
                        "name": f.name,
                        "episode": f.episode,
                        "season": f.season,
                        "subtitles": [{"path": s.path, "name": s.name, "language": s.language} for s in f.subtitles]
                    }
                    for f in v
                ]
                for k, v in cls.seasons.items()
            },
            "files": [
                {
                    "path": f.path,
                    "name": f.name,
                    "episode": f.episode,
                    "season": f.season,
                    "subtitles": [{"path": s.path, "name": s.name, "language": s.language} for s in f.subtitles]
                }
                for f in cls.files
            ]
        }
    
    classifications_list = [_classification_to_dict(cls) for cls in classifications.values()]
    
    # æ„å»ºå‰ç«¯æœŸæœ›çš„ classification_result æ ¼å¼ï¼ˆæŒ‰å­£æ˜¾ç¤ºï¼‰
    classification_result = {}
    for tmdb_id, cls in classifications.items():
        logger.info(f"ğŸ” æ„å»º classification_result: tmdb_id={tmdb_id}, type={cls.type}, name={cls.name}")
        if cls.type == MediaType.MOVIE:
            # ğŸ”¥ ç”µå½±ç±»å‹
            total_files = len(cls.files) + sum(len(files) for files in cls.seasons.values())
            try:
                item = ClassificationResultItem(
                    name=cls.name,
                    file_count=total_files,
                    ep_range="-",
                    type="movie",
                    seasons=None
                )
                logger.info(f"ğŸ” ç”µå½± item åˆ›å»ºæˆåŠŸ: {item.model_dump()}")
            except Exception as e:
                logger.error(f"ğŸ” ç”µå½± item åˆ›å»ºå¤±è´¥: {e}")
                raise
        else:
            # ğŸ”¥ TV ç±»å‹
            total_files = sum(len(files) for files in cls.seasons.values())
            
            # æŒ‰å­£æ„å»ºè¯¦æƒ…
            seasons_info = []
            all_eps = []
            for season_num, files in sorted(cls.seasons.items()):
                eps = [f.episode for f in files if f.episode > 0]
                if eps:
                    all_eps.extend(eps)
                    season_ep_range = f"E{min(eps):02d}-E{max(eps):02d}"
                    seasons_info.append(SeasonInfo(
                        season=season_num,
                        episode_count=len(eps),
                        ep_range=season_ep_range
                    ))
            
            # å…¼å®¹æ—§ç‰ˆçš„ ep_rangeï¼ˆæ‰€æœ‰å­£çš„ min-maxï¼‰
            ep_range = f"E{min(all_eps):02d}-E{max(all_eps):02d}" if all_eps else "-"
            
            try:
                item = ClassificationResultItem(
                    name=cls.name,
                    file_count=total_files,
                    ep_range=ep_range,
                    type="tv",
                    seasons=seasons_info  # ğŸ”¥ ç›´æ¥ä¼ é€’ SeasonInfo å¯¹è±¡åˆ—è¡¨
                )
                logger.info(f"ğŸ” TV item åˆ›å»ºæˆåŠŸ: {item.model_dump()}")
            except Exception as e:
                logger.error(f"ğŸ” TV item åˆ›å»ºå¤±è´¥: {e}, seasons_info={seasons_info}")
                raise
        classification_result[str(tmdb_id)] = item.model_dump()
    
    return make_tool_response(
        output,
        state_update={
            "classifications": classifications_list,
            "classification_result": classification_result,
        }
    )

